{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matakahas/portfolio/blob/main/Copy_of_speech_to_text_with_GUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXfByQ0TUw8h"
      },
      "source": [
        "## GUI-based speech-to-text tool \n",
        "\n",
        "The goal of this project is to develop a real-time speech-to-text (STT) tool with GUI functionality (using `Kivy`). <br>\n",
        "Reference：[https://www.dskomei.com/entry/2020/04/26/182100](https://www.dskomei.com/entry/2020/04/26/182100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfjPSOuYUw8m"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrLJ-F6UUw8n"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-speech\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "!pip install kivy[base] kivy_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zLz851hUUw8r",
        "outputId": "a88b510a-4298-4fef-ecd4-9dd7b0c0e05d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO   ] [Logger      ] Record log in /root/.kivy/logs/kivy_22-02-12_2.txt\n",
            "[INFO   ] [Kivy        ] v2.0.0\n",
            "[INFO   ] [Kivy        ] Installed at \"/usr/local/lib/python3.7/dist-packages/kivy/__init__.py\"\n",
            "[INFO   ] [Python      ] v3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "[GCC 7.5.0]\n",
            "[INFO   ] [Python      ] Interpreter at \"/usr/bin/python3\"\n",
            "[INFO   ] [Factory     ] 186 symbols loaded\n",
            "[INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
            "[INFO   ] [Text        ] Provider: sdl2\n"
          ]
        }
      ],
      "source": [
        "#packages used for real-time STT\n",
        "from __future__ import division\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import pyaudio\n",
        "import glob\n",
        "import json\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.cloud import speech\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from six.moves import queue\n",
        "import threading\n",
        "\n",
        "#packages used for GUI\n",
        "from kivy.app import App\n",
        "from kivy.config import Config\n",
        "from kivy.uix.label import Label\n",
        "from kivy.uix.widget import Widget\n",
        "from kivy.core.text import LabelBase, DEFAULT_FONT\n",
        "from kivy.properties import StringProperty \n",
        "from kivy.uix.boxlayout import BoxLayout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5frIQfcGUw8t"
      },
      "source": [
        "### Other required files\n",
        "* json file needed for API authentication\n",
        "* `speechtotext.kv`：To run an application built with Kivy, you need to have a python file specifying the configurations of GUI, and a Kivy file (with .kv extension) specifying the design of GUI. The Kivy file gets loaded automatically by giving it the name that is the lower-case version of the main class name on the python file (e.g., TestApp() → test.kv）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJcGjWnZUw8u"
      },
      "source": [
        "### Set the environmental variables of Google Speech-to-Text API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a7mWojDOUw8v"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./[your JSON service key name].json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEu2-57wUw8y"
      },
      "source": [
        "### Main code for conducting SST with GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "80QoaneZUw8z"
      },
      "outputs": [],
      "source": [
        "Config.set('graphics', 'fullscreen', 0)\n",
        "Config.set('graphics', 'width', str(1000))\n",
        "Config.set('graphics', 'height', str(300))\n",
        "\n",
        "STREAMING_LIMIT = 240000  \n",
        "SAMPLE_RATE = 16000\n",
        "CHUNK_SIZE = int(SAMPLE_RATE / 10)  \n",
        "\n",
        "speech_to_text_list = []\n",
        "stream_close = False\n",
        "\n",
        "class TextWidget(Widget):\n",
        "    text = StringProperty()\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TextWidget, self).__init__(**kwargs)\n",
        "        self.text = ''\n",
        "        self.number = 0   \n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TextWidget, self).__init__(**kwargs)\n",
        "        self.text = ''\n",
        "        self.number = 0\n",
        "\n",
        "\n",
        "    ## function that runs when the recording has started\n",
        "    def buttonClickedStart(self):        \n",
        "        t1 = threading.Thread(target=excecute_speech_to_text_streaming, args=(self,))\n",
        "        t1.start()\n",
        "\n",
        "\n",
        "    ## function that runs when the recording has stopped\n",
        "    def buttonClickedEnd(self):        \n",
        "        global stream_close\n",
        "        global speech_to_text_list\n",
        "\n",
        "        stream_close = True\n",
        "        \n",
        "        with open('./streaming_result.txt', 'w' ) as file:\n",
        "            text = '\\n'.join(speech_to_text_list)\n",
        "            file.writelines(text)\n",
        "\n",
        "        self.text = ''\n",
        "        speech_to_text_list = []\n",
        "\n",
        "        #exit()\n",
        "\n",
        "    def update(self):\n",
        "        self.text = display_texts(max_n_text=6)\n",
        "        \n",
        "\n",
        "class SpeechToTextApp(App):\n",
        "    def __init__(self, **kwargs):\n",
        "\n",
        "        super(SpeechToTextApp, self).__init__(**kwargs)\n",
        "        self.title = 'Speech to Text'\n",
        "\n",
        "    def build(self):\n",
        "        text_widget = TextWidget()\n",
        "        return text_widget\n",
        "\n",
        "\n",
        "## function that outputs a chunk of texts from the obtained transcriptions\n",
        "def display_texts(max_n_text=5):\n",
        "\n",
        "    if len(speech_to_text_list) <= max_n_text:\n",
        "        text = '\\n'.join(speech_to_text_list)\n",
        "    else:\n",
        "        text = '\\n'.join(speech_to_text_list[-max_n_text:])\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "class ResumableMicrophoneStream:\n",
        "\n",
        "    def __init__(self, rate, chunk_size):\n",
        "        \n",
        "        self._rate = rate\n",
        "        self.chunk_size = chunk_size\n",
        "        self._num_channels = 1\n",
        "    \n",
        "        self._buff = queue.Queue()                 \n",
        "\n",
        "        \n",
        "    def __enter__(self):\n",
        "\n",
        "        global stream_close\n",
        "        stream_close = False\n",
        "        self._audio_interface = pyaudio.PyAudio()\n",
        "        self._audio_stream = self._audio_interface.open(\n",
        "            format=pyaudio.paInt16,\n",
        "            channels=1,\n",
        "            rate=self._rate,\n",
        "            input=True,\n",
        "            frames_per_buffer=self.chunk_size,\n",
        "            stream_callback=self._fill_buffer,\n",
        "        )\n",
        "        \n",
        "        return self\n",
        "\n",
        "    \n",
        "    def __exit__(self, type, value, traceback):\n",
        "\n",
        "        self._audio_stream.stop_stream()\n",
        "        self._audio_stream.close()\n",
        "        self._buff.put(None)\n",
        "        self._audio_interface.terminate()\n",
        "        global stream_close\n",
        "        stream_close = True\n",
        "\n",
        "        \n",
        "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
        "\n",
        "        self._buff.put(in_data)\n",
        "        return None, pyaudio.paContinue\n",
        "\n",
        "    \n",
        "    def generator(self):\n",
        "\n",
        "        global stream_close\n",
        "        while not stream_close:\n",
        "            chunk = self._buff.get()\n",
        "            if chunk is None:\n",
        "                return\n",
        "            data = [chunk]\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    chunk = self._buff.get(block=False)\n",
        "                    if chunk is None:\n",
        "                        return\n",
        "                    data.append(chunk)\n",
        "                except queue.Empty:\n",
        "                    break\n",
        "\n",
        "            yield b\"\".join(data)\n",
        "\n",
        "\n",
        "\n",
        "def listen_print_loop(responses, stream, text_widget):\n",
        "    \n",
        "    global stream_close\n",
        "    global speech_to_text_list\n",
        "\n",
        "    for response in responses:\n",
        "        if stream_close:\n",
        "            break\n",
        "\n",
        "        if not response.results:\n",
        "            continue\n",
        "\n",
        "        result = response.results[0]\n",
        "\n",
        "        if not result.alternatives:\n",
        "            continue\n",
        "        \n",
        "        transcript = result.alternatives[0].transcript\n",
        "\n",
        "        if result.is_final:\n",
        "            speech_to_text_list[-1] = transcript\n",
        "            stream.last_transcript_was_final = True\n",
        "        else:\n",
        "            if len(speech_to_text_list) == 0:\n",
        "                speech_to_text_list.append(transcript)\n",
        "            else:\n",
        "                if stream.last_transcript_was_final:\n",
        "                    speech_to_text_list.append(transcript)\n",
        "                else:\n",
        "                    speech_to_text_list[-1] = transcript\n",
        "\n",
        "            stream.last_transcript_was_final = False\n",
        "        \n",
        "        text_widget.update()\n",
        "            \n",
        "    \n",
        "def excecute_speech_to_text_streaming(text_widget):\n",
        "\n",
        "    print('Start Speech to Text Streaming')\n",
        "\n",
        "    client = speech.SpeechClient()\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz=SAMPLE_RATE,\n",
        "        language_code='en-US',\n",
        "    )\n",
        "    streaming_config = speech.StreamingRecognitionConfig(\n",
        "        config=config, interim_results=True\n",
        "    )\n",
        "\n",
        "    mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)\n",
        "    with mic_manager as stream:\n",
        "        \n",
        "        audio_generator = stream.generator()\n",
        "\n",
        "        requests = (\n",
        "            speech.StreamingRecognizeRequest(audio_content=content)\n",
        "            for content in audio_generator\n",
        "        )\n",
        "\n",
        "        responses = client.streaming_recognize(streaming_config, requests)\n",
        "        \n",
        "        listen_print_loop(responses, stream, text_widget)\n",
        "\n",
        "    print('End Speech to Text Streaming')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   print('hi')\n",
        "   #SpeechToTextApp().run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZpL__5LqfxG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of speech_to_text_with_GUI.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}